{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db5943-3c1a-4135-bf4f-93a4f43fdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web scraping is a process of extracting data from websites. It is used to extract data from websites and store it in a structured format for further analysis. Web scraping is used to get data from websites for various purposes such as market research, price comparison, competitive analysis, and more. Three areas where web scraping is used to get data include:\n",
    "\n",
    "\n",
    "Online Shopping: Web scraping can be used to collect product information from online stores such as prices, availability, reviews, and more.\n",
    "Social Media: Web scraping can be used to collect data from social media platforms such as Twitter, Facebook, and Instagram. This data can be used for sentiment analysis or to gain insights into user behavior.\n",
    "News Aggregators: Web scraping can be used to collect news articles from various sources and aggregate them into one place. This can be used to create a personalized news feed or to track the latest news in a particular topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5fd51-2101-441d-91af-4d0c19270627",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML Parsing: HTML parsing is used to extract data from a particular website by parsing the HTML code of the website.\n",
    "Screen Scraping: Screen scraping is used to extract data from a particular website by taking screenshots of the website and then using OCR (Optical Character Recognition) to extract the data from the screenshots.\n",
    "API: API (Application Programming Interface) is used to extract data from a particular website by using specific API calls.\n",
    "Regular Expressions: Regular expressions are used to extract data from a particular website by using specific patterns in the text of the website.\n",
    "Web Crawling: Web crawling is used to extract data from a particular website by crawling through the different pages of the website and extracting the relevant data from each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10019c-6cb2-4d45-8417-4d55013971c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beautiful Soup is a Python library for parsing HTML and XML documents. It is used to extract data from HTML documents, such as webpages, and can be used to parse and modify the HTML code of a webpage. It is used to quickly extract data from webpages, which can then be used for further analysis or manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f74f0b-62bd-430a-b1c7-61d720b9039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask is used in this Web Scraping project because it is a lightweight web application framework that can be used to build web applications quickly and easily. It is also easy to use and has a wide range of features that make it suitable for a variety of web development tasks. Flask also provides an easy way to create a basic web application with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12fb76-1dce-4a4b-9a3d-541cf9b31e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon Elastic Compute Cloud (EC2): EC2 is a web service that provides resizable compute capacity in the cloud. It is used in this project to launch virtual servers that host the web application.\n",
    "Amazon Simple Storage Service (S3): S3 is an object storage service that provides secure, durable, and highly-scalable storage for data and applications. It is used in this project to store static files such as images, videos, and other media.\n",
    "Amazon Relational Database Service (RDS): RDS is a managed relational database service that provides a secure and cost-effective way to store data. It is used in this project to store the applicationâ€™s data.\n",
    "Amazon CloudFront: CloudFront is a content delivery network (CDN) that speeds up the delivery of static content such as images, videos, and other media. It is used in this project to improve the performance of the web application by caching content closer to users.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
